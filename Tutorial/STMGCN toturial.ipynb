{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time,psutil,tracemalloc\n",
    "from loss import target_distribution, kl_loss\n",
    "from util import *\n",
    "import argparse\n",
    "from models import *\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_mutual_info_score,adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "import psutil,tracemalloc\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mk_dir(input_path):\n",
    "    if not os.path.exists(input_path):\n",
    "        os.makedirs(input_path)\n",
    "    return input_path\n",
    "\n",
    "def train_MSpaGCN(opts):\n",
    "    start = time.time()\n",
    "    start_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024\n",
    "\n",
    "    if opts.dataset.startswith('15'):\n",
    "        features_adata,features,labels = load_data(opts.dataset,opts.npca)\n",
    "    else:\n",
    "\n",
    "        features_adata, features, labels = load_other_data(opts.dataset, opts.input_root,opts.npca)\n",
    "\n",
    "    adj1, adj2 = load_graph_V1(opts.dataset, features_adata,opts.l)\n",
    "\n",
    "\n",
    "    model =STMGCN(nfeat=features.shape[1],\n",
    "                    nhid1=opts.nhid1,\n",
    "                    nclass=opts.n_cluster\n",
    "                    )\n",
    "    if opts.cuda:\n",
    "        model.cuda()\n",
    "        features = features.cuda()\n",
    "        adj1 = adj1.cuda()\n",
    "        adj2 = adj2.cuda()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),lr=opts.lr, weight_decay=opts.weight_decay)\n",
    "    emb = model.mgcn(features,adj1,adj2) #(3639,32)\n",
    "\n",
    "\n",
    "    if opts.initcluster == \"kmeans\":\n",
    "        print(\"Initializing cluster centers with kmeans, n_clusters known\")\n",
    "        n_clusters=opts.n_cluster\n",
    "        kmeans = KMeans(n_clusters,n_init=20)\n",
    "        y_pred = kmeans.fit_predict(emb.detach().cpu().numpy())\n",
    "\n",
    "    elif opts.initcluster == \"louvain\":\n",
    "        print(\"Initializing cluster centers with louvain,resolution=\",opts.res)\n",
    "        adata=sc.AnnData(emb.detach().cpu().numpy())\n",
    "        sc.pp.neighbors(adata, n_neighbors=opts.n_neighbors)\n",
    "        sc.tl.louvain(adata,resolution=opts.res)\n",
    "        y_pred=adata.obs['louvain'].astype(int).to_numpy()\n",
    "        n=len(np.unique(y_pred))\n",
    "\n",
    "\n",
    "\n",
    "    emb=pd.DataFrame(emb.detach().cpu().numpy(),index=np.arange(0,emb.shape[0]))\n",
    "    Group=pd.Series(y_pred,index=np.arange(0,emb.shape[0]),name=\"Group\")\n",
    "    Mergefeature=pd.concat([emb,Group],axis=1)\n",
    "    cluster_centers=np.asarray(Mergefeature.groupby(\"Group\").mean())\n",
    "\n",
    "    y_pred_last = y_pred\n",
    "    with torch.no_grad():\n",
    "        model.cluster_layer.copy_(torch.tensor(cluster_centers))\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(opts.max_epochs):\n",
    "\n",
    "        if epoch % opts.update_interval == 0:\n",
    "            _, tem_q = model(features,adj1,adj2)\n",
    "            tem_q = tem_q.detach() #calculate q\n",
    "            p = target_distribution(tem_q) #calculate p\n",
    "\n",
    "            y_pred = torch.argmax(tem_q, dim=1).cpu().numpy()\n",
    "            delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "            y_pred_last = y_pred\n",
    "            y = labels #【-1，6】\n",
    "\n",
    "            nmi = normalized_mutual_info_score(y, y_pred)\n",
    "            ari = adjusted_mutual_info_score(y, y_pred)\n",
    "\n",
    "            print('Iter {}'.format(epoch), ', nmi {:.4f}'.format(nmi), ', ari {:.4f}'.format(ari))\n",
    "\n",
    "            if epoch>0 and delta_label < opts.tol:\n",
    "                print('delta_label ', delta_label, '< tol ', opts.tol)\n",
    "                print(\"Reach tolerance threshold. Stopping training.\")\n",
    "                break\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        x,q = model(features,adj1,adj2)\n",
    "        loss = kl_loss(q.log(), p)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    #save emnddings\n",
    "    key_added = \"STMGCN\"\n",
    "    embeddings = pd.DataFrame(x.detach().cpu().numpy())\n",
    "    embeddings.index = features_adata.obs_names\n",
    "\n",
    "    features_adata.obsm[key_added] = embeddings.loc[features_adata.obs_names,].values\n",
    "    features_adata.obs['pred']=y_pred_last\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    end_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024  #\n",
    "    used_memory = end_MB - start_MB\n",
    "\n",
    "    ari, nmi, ami = eval_model(y_pred_last, features_adata.obs['Ground Truth'])\n",
    "    SC = silhouette_score(embeddings, y_pred_last)\n",
    "\n",
    "    used_adata = features_adata[features_adata.obs[\"Ground Truth\"].notna()]\n",
    "    SC_revise = silhouette_score(used_adata.obsm[\"STMGCN\"], used_adata.obs['Ground Truth'])\n",
    "\n",
    "    print(f\"sc{SC:5f}\")\n",
    "    results_df = pd.DataFrame()\n",
    "    res = {}\n",
    "    res[\"dataset\"] = dataset\n",
    "    res[\"ari\"] = ari\n",
    "    res[\"nmi\"] = nmi\n",
    "    res[\"ami\"] = ami\n",
    "    res[\"sc\"] = SC\n",
    "    res[\"time\"] = end-start\n",
    "    res['Memo']=used_memory\n",
    "    res[\"sc_revise\"]=SC_revise\n",
    "    return features_adata,res\n",
    "\n",
    "def parser_set(n_cluster,dataset):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False)\n",
    "    parser.add_argument('--lr',type=float,default=0.001)\n",
    "    parser.add_argument('--nhid1',type=int,default=32)\n",
    "    parser.add_argument('--n_cluster',default=n_cluster,type=int)\n",
    "    parser.add_argument('--max_epochs',default=2000,type=int) #2000\n",
    "    parser.add_argument('--update_interval',default= 3,type=int)\n",
    "    parser.add_argument('--seed', type=int, default=50)\n",
    "    parser.add_argument('--weight_decay',default=0.001,type=float)\n",
    "    parser.add_argument('--dataset', type=str, default=dataset)\n",
    "    # parser.add_argument('--sicle', default=\"151673\", type=str)\n",
    "    parser.add_argument('--tol', default=0.0001, type=float)\n",
    "    parser.add_argument('--l', default=1, type=float)\n",
    "    parser.add_argument('--npca', default=50, type=int)\n",
    "    parser.add_argument('--n_neighbors',type=int,default=10)\n",
    "    parser.add_argument('--initcluster', default=\"kmeans\", type=str)\n",
    "    parser.add_argument('--input_root', default=f'../../Dataset/', type=str)\n",
    "    parser.add_argument('--output_root', default=f'../../Output/', type=str)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    args.cuda = torch.cuda.is_available()\n",
    "    print(\"use cuda: {}\".format(args.cuda))\n",
    "\n",
    "\n",
    "    args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    args.device = torch.device('cuda' if args.cuda else 'cpu')\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "    return args\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================begin test on 151673======================================\n",
      "151673 has 7 cluster type!\n"
     ]
    }
   ],
   "source": [
    "n_clusters_map = {\"Mouse_hippocampus\": 10, \"Mouse_olfactory_slide_seqv2\": 9, \"MOB_without_label\": 7,\n",
    "                  \"PDAC\": 4, \"Breast_cancer\": 20, \"Mouse_brain\": 15,\n",
    "                  \"SeqFish\": 22, \"STARmap\": 16,\"Stereo\":16}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = [\"Mouse_brain\", \"Breast_cancer\", \"PDAC\", \"Stereo\", \"STARmap\"]\n",
    "    dataset2 = ['151507', '151508', '151509', '151510', '151669', '151670', '151671', '151672', '151673', '151674','151675', '151676']\n",
    "    Dataset_test=['151673']\n",
    "for dataset in Dataset_test:\n",
    "    print(f\"====================begin test on {dataset}======================================\")\n",
    "    if dataset.startswith('15'):\n",
    "        n_domains = 5 if dataset in ['151669', '151670', '151671', '151672'] else 7\n",
    "        save_data_path = f'../../Output/STMGCN/DLPFC/{dataset}/'\n",
    "    else:\n",
    "        n_domains = n_clusters_map[dataset]\n",
    "        save_data_path = f'../../Output/STMGCN/{dataset}/'\n",
    "    mk_dir(save_data_path)\n",
    "    print(f\"{dataset} has {n_domains} cluster type!\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    opts = parser_set(n_domains,dataset)\n",
    "    print(opts)\n",
    "\n",
    "    results_df=pd.DataFrame()\n",
    "    for i in range(1):\n",
    "        random_seed = 0\n",
    "        start = time.time()\n",
    "        tracemalloc.start()\n",
    "        start_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024\n",
    "\n",
    "        adata,res=train_MSpaGCN(opts)\n",
    "        end = time.time()\n",
    "        end_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024\n",
    "        uesd_time = end - start\n",
    "        used_memo = end_MB - start_MB\n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        tracemalloc.stop()\n",
    "        peak = peak / 1024.0 / 1024.0 / 1024.0\n",
    "        print(u'Current memory usage_end:：%.4f GB' % used_memo)\n",
    "        print('time: {:.4f} s'.format(uesd_time))\n",
    "        print('memory blocks peak:{:>10.4f} GB'.format(peak))\n",
    "        tracemalloc.clear_traces()\n",
    "\n",
    "        res[\"time\"] = uesd_time\n",
    "        res[\"Memo\"] = used_memo\n",
    "        res[\"Memo_peak\"] = peak\n",
    "        res[\"round\"] = i + 1\n",
    "        results_df = results_df._append(res, ignore_index=True)\n",
    "\n",
    "\n",
    "    print( results_df.head())\n",
    "\n",
    "    results_df.to_csv(save_data_path + \"/{}_result.csv\".format(dataset), header=True)\n",
    "    adata.write(f'{save_data_path}/STMGCN_{dataset}.h5ad')\n",
    "\n",
    "\n",
    "    results_df.set_index('dataset', inplace=True)\n",
    "    res_mean = results_df.mean()\n",
    "    res_mean.to_csv(f'{save_data_path}{dataset}_mean.csv', header=True)\n",
    "    res_std =results_df.std()\n",
    "    res_std.to_csv(f'{save_data_path}{dataset}_std.csv', header=True)\n",
    "    res_median = results_df.median()\n",
    "    res_median.to_csv(f'{save_data_path}{dataset}_median.csv', header=True)  #\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
