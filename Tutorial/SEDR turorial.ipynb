{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import warnings\n",
    "import numpy as np\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.graph_func import graph_construction\n",
    "from src.utils_func import mk_dir, adata_preprocess, load_visium_sge\n",
    "from src.SEDR_train import SEDR_Train\n",
    "from util import get_adata,mk_dir,eval_model\n",
    "from sklearn.metrics import silhouette_score\n",
    "import time\n",
    "import psutil\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.cuda.cudnn_enabled = False\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "import psutil,time,tracemalloc\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('===== Using device: ' + device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def res_search_fixed_clus(adata, fixed_clus_count, increment=0.02):\n",
    "    '''\n",
    "        arg1(adata)[AnnData matrix]\n",
    "        arg2(fixed_clus_count)[int]\n",
    "\n",
    "        return:\n",
    "            resolution[int]\n",
    "    '''\n",
    "    for res in sorted(list(np.arange(0.2, 2.5, increment)), reverse=True):\n",
    "        sc.tl.leiden(adata, random_state=0, resolution=res)\n",
    "        count_unique_leiden = len(pd.DataFrame(adata.obs['leiden']).leiden.unique())\n",
    "        if count_unique_leiden == fixed_clus_count:\n",
    "            break\n",
    "    return res\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def run_SEDR(adata_h5,save_path,epochs):\n",
    "    # ################ Parameter setting\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--k', type=int, default=10, help='parameter k in spatial graph')\n",
    "    parser.add_argument('--knn_distanceType', type=str, default='euclidean',\n",
    "                        help='graph distance type: euclidean/cosine/correlation')\n",
    "    parser.add_argument('--epochs', type=int, default=epochs, help='Number of epochs to train.') #default=200\n",
    "    parser.add_argument('--cell_feat_dim', type=int, default=200, help='Dim of PCA')\n",
    "    parser.add_argument('--feat_hidden1', type=int, default=100, help='Dim of DNN hidden 1-layer.')\n",
    "    parser.add_argument('--feat_hidden2', type=int, default=20, help='Dim of DNN hidden 2-layer.')\n",
    "    parser.add_argument('--gcn_hidden1', type=int, default=32, help='Dim of GCN hidden 1-layer.')\n",
    "    parser.add_argument('--gcn_hidden2', type=int, default=8, help='Dim of GCN hidden 2-layer.')\n",
    "    parser.add_argument('--p_drop', type=float, default=0.2, help='Dropout rate.')\n",
    "    parser.add_argument('--using_dec', type=bool, default=True, help='Using DEC loss.')\n",
    "    parser.add_argument('--using_mask', type=bool, default=False, help='Using mask for multi-dataset.')\n",
    "    parser.add_argument('--feat_w', type=float, default=10, help='Weight of DNN loss.')\n",
    "    parser.add_argument('--gcn_w', type=float, default=0.1, help='Weight of GCN loss.')\n",
    "    parser.add_argument('--dec_kl_w', type=float, default=10, help='Weight of DEC loss.')\n",
    "    parser.add_argument('--gcn_lr', type=float, default=0.01, help='Initial GNN learning rate.')\n",
    "    parser.add_argument('--gcn_decay', type=float, default=0.01, help='Initial decay rate.')\n",
    "    parser.add_argument('--dec_cluster_n', type=int, default=10, help='DEC cluster number.')\n",
    "    parser.add_argument('--dec_interval', type=int, default=20, help='DEC interval nnumber.')\n",
    "    parser.add_argument('--dec_tol', type=float, default=0.00, help='DEC tol.')\n",
    "    # ______________ Eval clustering Setting _________\n",
    "    parser.add_argument('--eval_resolution', type=int, default=1, help='Eval cluster number.')\n",
    "    parser.add_argument('--eval_graph_n', type=int, default=20, help='Eval graph kN tol.')\n",
    "\n",
    "    params = parser.parse_args()\n",
    "    params.device = device\n",
    "\n",
    "    params.cell_num = adata_h5.shape[0]\n",
    "    params.save_path = mk_dir(save_path)\n",
    "\n",
    "    start = time.time()\n",
    "    start_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024\n",
    "\n",
    "    adata_X = adata_preprocess(adata_h5, min_cells=5, pca_n_comps=params.cell_feat_dim)\n",
    "    graph_dict = graph_construction(adata_h5.obsm['spatial'], adata_h5.shape[0], params)\n",
    "    params.cell_num = adata_h5.shape[0]\n",
    "    params.save_path = mk_dir(save_path)\n",
    "\n",
    "\n",
    "    print('==== Graph Construction Finished')\n",
    "    # ################## Model training\n",
    "    sedr_net = SEDR_Train(adata_X, graph_dict, params)\n",
    "    if params.using_dec:\n",
    "        sedr_net.train_with_dec()\n",
    "    else:\n",
    "        sedr_net.train_without_dec()\n",
    "    sedr_feat, _, _, _ = sedr_net.process()\n",
    "\n",
    "    # ################## Result plot\n",
    "    adata_sedr = anndata.AnnData(sedr_feat)\n",
    "    if dataset in [\"Mouse_brain\",\"Breast_cancer\"]:\n",
    "        adata_sedr.uns['spatial'] = adata_h5.uns['spatial']\n",
    "        adata_sedr.obsm['spatial'] = adata_h5.obsm['spatial']\n",
    "    else:\n",
    "         print(\"no spatial information\")\n",
    "\n",
    "    adata_sedr.obs['ground_truth'] = adata_h5.obs['ground_truth'].values\n",
    "    sc.pp.neighbors(adata_sedr, n_neighbors=params.eval_graph_n)\n",
    "    sc.tl.umap(adata_sedr)\n",
    "    eval_resolution = res_search_fixed_clus(adata_sedr, n_cluster)\n",
    "    sc.tl.leiden(adata_sedr, key_added=\"SEDR_leiden\", resolution=eval_resolution)\n",
    "\n",
    "    adata_sedr.write_h5ad(f'{save_path}{dataset}.h5ad')\n",
    "\n",
    "    if dataset in ['Mouse_brain,Breast_cancer']:\n",
    "        sc.pl.spatial(adata_sedr, img_key=\"hires\", color=['SEDR_leiden'], show=False)\n",
    "        plt.savefig(os.path.join(params.save_path, \"SEDR_leiden_plot.pdf\"), bbox_inches='tight', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # ---------- Load manually annotation ---------------\n",
    "    ari, nmi, ami = eval_model(adata_sedr.obs['SEDR_leiden'], adata_sedr.obs['ground_truth'])\n",
    "    SC = silhouette_score(adata_sedr.X, adata_sedr.obs['SEDR_leiden'])\n",
    "    used_adata = adata_sedr[adata_sedr.obs[\"ground_truth\"].notna()]\n",
    "    res = {}\n",
    "    res[\"dataset\"] = dataset\n",
    "    res[\"ari\"] = ari\n",
    "    res[\"nmi\"] = nmi\n",
    "    res[\"ami\"] = ami\n",
    "    res[\"sc\"] = SC\n",
    "    return res\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load DLPFC dataset:\n",
      "===Training epoch:1====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--k K]\n",
      "                             [--knn_distanceType KNN_DISTANCETYPE]\n",
      "                             [--epochs EPOCHS] [--cell_feat_dim CELL_FEAT_DIM]\n",
      "                             [--feat_hidden1 FEAT_HIDDEN1]\n",
      "                             [--feat_hidden2 FEAT_HIDDEN2]\n",
      "                             [--gcn_hidden1 GCN_HIDDEN1]\n",
      "                             [--gcn_hidden2 GCN_HIDDEN2] [--p_drop P_DROP]\n",
      "                             [--using_dec USING_DEC] [--using_mask USING_MASK]\n",
      "                             [--feat_w FEAT_W] [--gcn_w GCN_W]\n",
      "                             [--dec_kl_w DEC_KL_W] [--gcn_lr GCN_LR]\n",
      "                             [--gcn_decay GCN_DECAY]\n",
      "                             [--dec_cluster_n DEC_CLUSTER_N]\n",
      "                             [--dec_interval DEC_INTERVAL] [--dec_tol DEC_TOL]\n",
      "                             [--eval_resolution EVAL_RESOLUTION]\n",
      "                             [--eval_graph_n EVAL_GRAPH_N]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Lenovo\\AppData\\Roaming\\jupyter\\runtime\\kernel-e18b5227-1509-43ef-9148-3a13181d2e2b.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\u001B[1;31m:\u001B[0m 2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils_for_all as usa\n",
    "if __name__ == '__main__':\n",
    " # Dataset1 = ['151507', '151508', '151509', '151510', '151669', '151670','151671', '151672', '151673', '151674', '151675', '151676',\"STARmap\",\"ST_Hippocampus_2\",'SlideV2_mouse_embryo_E8.5','151673',\"SeqFish\",\"Stereo\"]\n",
    "  Dataset_test=['151673']\n",
    "\n",
    "for dataset in Dataset_test:\n",
    "    data_root = os.path.join(\"../../Dataset/\", dataset)\n",
    "    save_path = os.path.join(\"../../Output/SEDR/\", dataset)\n",
    "    adata_h5, n_cluster = usa.get_adata(dataset, data_path='../../Dataset/')\n",
    "    adata_h5.var_names_make_unique()\n",
    "    results = pd.DataFrame()\n",
    "    for i in range(1):\n",
    "        num = i + 1\n",
    "        print(\"===Training epoch:{}====\".format(num))\n",
    "        start = time.time()\n",
    "        tracemalloc.start()\n",
    "        start_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024\n",
    "        res=run_SEDR(adata_h5,save_path,epochs=200)\n",
    "\n",
    "        end = time.time()\n",
    "        end_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024\n",
    "        uesd_time = end - start\n",
    "        used_memo = end_MB - start_MB\n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        tracemalloc.stop()\n",
    "        peak = peak / 1024.0 / 1024.0 / 1024.0\n",
    "        print(u'Current memory usage_end:：%.4f GB' % used_memo)\n",
    "        print('time: {:.4f} s'.format(uesd_time))\n",
    "        print('memory blocks peak:{:>10.4f} GB'.format(peak))\n",
    "        tracemalloc.clear_traces()\n",
    "\n",
    "        res[\"time\"] = uesd_time\n",
    "        res[\"Memo\"] = used_memo\n",
    "        res[\"Memo_peak\"] = peak\n",
    "        res[\"round\"] = num\n",
    "\n",
    "        results = results._append(res, ignore_index=True)\n",
    "    results.set_index('dataset', inplace=True)\n",
    "    print(results.head())\n",
    "    results.to_csv(os.path.join(save_path, \"result_scores.csv\"))\n",
    "\n",
    "    res_mean = results.mean()\n",
    "    res_mean.to_csv(f'{save_path}/{dataset}_mean.csv', header=True)\n",
    "    res_std = results.std()\n",
    "    res_std.to_csv(f'{save_path}/{dataset}_std.csv', header=True)\n",
    "    res_median = results.median()\n",
    "    res_median.to_csv(f'{save_path}/{dataset}_median.csv', header=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
