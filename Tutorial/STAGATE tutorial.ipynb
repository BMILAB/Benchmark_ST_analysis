{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "from sklearn.metrics.cluster import adjusted_rand_score,normalized_mutual_info_score,adjusted_mutual_info_score,silhouette_score\n",
    "import squidpy as sq\n",
    "import time,psutil,tracemalloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#Be sure that R_HOME is included in the environment variant. Otherwise it needs to be defined here\n",
    "os.environ[\"R_HOME\"] = r\"D:\\R-4.3.1\"\n",
    "os.environ[\"PATH\"]   = r\"D:\\R-4.3.1\\bin\\x64\" + \";\" + os.environ[\"PATH\"]\n",
    "\n",
    "def mk_dir(input_path):\n",
    "    if not os.path.exists(input_path):\n",
    "        os.makedirs(input_path)\n",
    "    return input_path\n",
    "\n",
    "def eval_model(pred, labels=None):\n",
    "    if labels is not None:\n",
    "        label_df = pd.DataFrame({\"True\": labels, \"Pred\": pred}).dropna()\n",
    "        ari = adjusted_rand_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        nmi = normalized_mutual_info_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        ami=adjusted_mutual_info_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "    return  ari,nmi,ami\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def run_STAGATE(adata, dataset, random_seed=np.random.randint(100),\n",
    "                device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
    "                save_data_path=\"/home/sda1/fangzy/data/st_data/Benchmark/STAGATE/\",\n",
    "                n_clusters=None, rad_cutoff=150):\n",
    "    import STAGATE_pyG as STAGATE\n",
    "    start = time.time()\n",
    "    start_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024\n",
    "    sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "    STAGATE.Cal_Spatial_Net(adata, rad_cutoff=rad_cutoff)\n",
    "    STAGATE.Stats_Spatial_Net(adata)\n",
    "    adata = STAGATE.train_STAGATE(adata, device=device, random_seed=random_seed)\n",
    "    sc.pp.neighbors(adata, use_rep='STAGATE')\n",
    "    sc.tl.umap(adata)\n",
    "\n",
    "    if (\"ground_truth\" in adata.obs.keys()):\n",
    "        n_clusters = len(set(adata.obs[\"ground_truth\"].dropna()))\n",
    "    else:\n",
    "        n_clusters = n_clusters\n",
    "    adata = STAGATE.mclust_R(adata, used_obsm='STAGATE', num_cluster=n_clusters)\n",
    "\n",
    "    obs_df = adata.obs.dropna()\n",
    "    adata.obs[\"pred_label\"] = adata.obs[\"mclust\"]\n",
    "    adata.obsm[\"embedding\"] = adata.obsm[\"STAGATE\"]\n",
    "\n",
    "    res = {}\n",
    "    if (\"ground_truth\" in adata.obs.keys()):\n",
    "        ari, nmi, ami = eval_model(adata.obs['mclust'], adata.obs['ground_truth'])\n",
    "        SC = silhouette_score(adata.obsm[\"embedding\"],adata.obs['mclust'])\n",
    "\n",
    "        used_adata = adata[adata.obs[\"ground_truth\"].notna()]\n",
    "        SC_revise = silhouette_score(used_adata.obsm[\"embedding\"], used_adata.obs['ground_truth'])\n",
    "\n",
    "        end = time.time()\n",
    "        end_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024  #\n",
    "        used_memory = end_MB - start_MB\n",
    "\n",
    "        res = {}\n",
    "        res[\"dataset\"] = dataset\n",
    "        res[\"ari\"] = ari\n",
    "        res[\"nmi\"] = nmi\n",
    "        res[\"ami\"] = ami\n",
    "        res[\"sc\"] = SC\n",
    "        res[\"time\"] = end - start\n",
    "        res[\"Memo\"] = used_memory\n",
    "        res['SC_revise']=SC_revise\n",
    "\n",
    "    # adata.write_h5ad(save_data_path+str(dataset)+\".h5ad\")\n",
    "    return res, adata\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage_end:：0.0000 GB\n",
      "time: 0.0000 s\n",
      "memory blocks peak:    0.0000 GB\n",
      "====================begin test on 151673======================================\n",
      "load DLPFC dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_install\\envs\\STAGATE\\lib\\site-packages\\anndata\\_core\\anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===epoch:1===\n",
      "------Calculating spatial graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_install\\envs\\STAGATE\\lib\\site-packages\\STAGATE_pyG\\utils.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Spatial_Net['Cell1'] = Spatial_Net['Cell1'].map(id_cell_trans)\n",
      "D:\\Anaconda_install\\envs\\STAGATE\\lib\\site-packages\\STAGATE_pyG\\utils.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Spatial_Net['Cell2'] = Spatial_Net['Cell2'].map(id_cell_trans)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph contains 21124 edges, 3639 cells.\n",
      "5.8049 neighbors per cell on average.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [01:33<00:00,  4.26it/s]\n",
      "R[write to console]:                    __           __ \n",
      "   ____ ___  _____/ /_  _______/ /_\n",
      "  / __ `__ \\/ ___/ / / / / ___/ __/\n",
      " / / / / / / /__/ / /_/ (__  ) /_  \n",
      "/_/ /_/ /_/\\___/_/\\__,_/____/\\__/   version 6.0.0\n",
      "Type 'citation(\"mclust\")' for citing this R package in publications.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting ...\n",
      "  |======================================================================| 100%\n",
      "Current memory usage_end:：16.0069 GB\n",
      "time: 122.0316 s\n",
      "memory blocks peak:    0.3739 GB\n",
      "              ari       nmi       ami        sc        time       Memo  \\\n",
      "dataset                                                                  \n",
      "151673   0.591607  0.716298  0.715533  0.185218  122.031552  16.006878   \n",
      "\n",
      "         SC_revise  Memo_peak  round  \n",
      "dataset                               \n",
      "151673    0.131393   0.373933      1  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils_for_all as usa\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # dataset1 = [\"Stereo\", \"Breast_cancer\", \"Mouse_brain\", \"STARmap\", \"SeqFish\", \"STARmap\"]\n",
    "    Dataset_test = ['151673']\n",
    "for dataset in Dataset_test:\n",
    "    print(f\"====================begin test on {dataset}======================================\")\n",
    "    if dataset.startswith('15'):\n",
    "        save_path = f'../../Output/STAGATE/DLPFC/{dataset}/'\n",
    "    else:\n",
    "        save_path = f'../../Output/STAGATE/{dataset}/'\n",
    "    mk_dir(save_path)\n",
    "\n",
    "    adata, n_clusters = usa.get_adata(dataset, data_path='../../Dataset/')\n",
    "    adata.var_names_make_unique()\n",
    "\n",
    "    random_seed = 0\n",
    "    rad_cutoff = 150\n",
    "    results = pd.DataFrame()\n",
    "    for i in range(1):\n",
    "        num = i + 1\n",
    "        print(\"===epoch:{}===\".format(num))\n",
    "        start = time.time()\n",
    "        tracemalloc.start()\n",
    "        start_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024\n",
    "        res, adata_h5 = run_STAGATE(adata.copy(), dataset, random_seed=random_seed, rad_cutoff=rad_cutoff,n_clusters= n_clusters)\n",
    "\n",
    "        end = time.time()\n",
    "        end_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024\n",
    "        uesd_time = end - start\n",
    "        used_memo = end_MB - start_MB\n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        tracemalloc.stop()\n",
    "        peak = peak / 1024.0 / 1024.0 / 1024.0\n",
    "        print(u'Current memory usage_end:：%.4f GB' % used_memo)\n",
    "        print('time: {:.4f} s'.format(uesd_time))\n",
    "        print('memory blocks peak:{:>10.4f} GB'.format(peak))\n",
    "        tracemalloc.clear_traces()\n",
    "\n",
    "        res[\"time\"] = uesd_time\n",
    "        res[\"Memo\"] = used_memo\n",
    "        res[\"Memo_peak\"] = peak\n",
    "        res[\"round\"] = i + 1\n",
    "        results = results._append(res, ignore_index=True)\n",
    "\n",
    "    adata_h5.write_h5ad(save_path + str(dataset) + \".h5ad\")\n",
    "    results.set_index('dataset', inplace=True)\n",
    "    results.to_csv(save_path +\"/result_\"+dataset+\".csv\", header=True)\n",
    "    print(results.head())\n",
    "    res_mean = results.mean()\n",
    "    res_mean.to_csv(f'{save_path}{dataset}_mean.csv', header=True)\n",
    "    res_std = results.std()\n",
    "    res_std.to_csv(f'{save_path}{dataset}_std.csv', header=True)\n",
    "    res_median = results.median()\n",
    "    res_median.to_csv(f'{save_path}{dataset}_median.csv', header=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
