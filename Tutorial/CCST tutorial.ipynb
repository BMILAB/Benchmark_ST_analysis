{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, normalized_mutual_info_score,adjusted_mutual_info_score,silhouette_score\n",
    "import time\n",
    "import psutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate Clustering Indicator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def mk_dir(input_path):\n",
    "    if not os.path.exists(input_path):\n",
    "        os.makedirs(input_path)\n",
    "    return input_path\n",
    "\n",
    "def eval_model(pred, labels=None):\n",
    "    if labels is not None:\n",
    "        label_df = pd.DataFrame({\"True\": labels, \"Pred\": pred}).dropna()\n",
    "        # label_df = pd.DataFrame({\"True\": labels, \"Pred\": pred}).dropna()\n",
    "        # completeness = completeness_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        # hm = homogeneity_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        # vm = v_measure_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        ari = adjusted_rand_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        nmi = normalized_mutual_info_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        ami=adjusted_mutual_info_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "\n",
    "    return ari, nmi,ami"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, you need to run `data_generation_ST_realdata.py` to preprocess the data and save it under the corresponding `\\Dataset\\CCST_generate_dataset` file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "def run_CCST(data_name, n_clusters,read_data_path,save_data_path):\n",
    "    import os\n",
    "    import sys\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    from torch_geometric.nn import GCNConv, ChebConv, GATConv, DeepGraphInfomax, global_mean_pool, global_max_pool  # noqa\n",
    "    rootPath = os.path.dirname(sys.path[0]) #  sys.path[0] Returns the current path，os.path.dirname denotes the parent path of the current path\n",
    "    os.chdir(rootPath+'/CCST')\n",
    "\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # ================Specify data type firstly===============\n",
    "    parser.add_argument('--data_type', default='nsc', help='\"sc\" or \"nsc\", \\\n",
    "        refers to single cell resolution datasets(e.g. MERFISH) and \\\n",
    "        non single cell resolution data(e.g. ST) respectively')\n",
    "    # =========================== args ===============================\n",
    "    parser.add_argument('--data_name', type=str, default=data_name,\n",
    "                        help=\"'MERFISH' or 'V1_Breast_Cancer_Block_A_Section_1\")\n",
    "    # 0.8 on MERFISH, 0.3 on ST\n",
    "    parser.add_argument('--lambda_I', type=float, default=0.3)\n",
    "    parser.add_argument('--data_path', type=str,\n",
    "                        default=read_data_path, help='data path')\n",
    "    parser.add_argument('--save_path', type=str,\n",
    "                        default=save_data_path, help='data path')\n",
    "\n",
    "    parser.add_argument('--model_path', type=str, default='model')\n",
    "    parser.add_argument('--embedding_data_path', type=str,\n",
    "                        default='Embedding_data')\n",
    "    parser.add_argument('--result_path', type=str, default='results')\n",
    "    parser.add_argument('--DGI', type=int, default=1,\n",
    "                        help='run Deep Graph Infomax(DGI) model, otherwise direct load embeddings')\n",
    "    parser.add_argument('--load', type=int, default=0,\n",
    "                        help='Load pretrained DGI model')\n",
    "    parser.add_argument('--num_epoch', type=int, default=5000,\n",
    "                        help='numebr of epoch in training DGI') #5000\n",
    "    parser.add_argument('--hidden', type=int, default=256,\n",
    "                        help='hidden channels in DGI')\n",
    "    parser.add_argument('--PCA', type=int, default=1, help='run PCA or not')\n",
    "    parser.add_argument('--cluster', type=int, default=1,\n",
    "                        help='run cluster or not')\n",
    "    parser.add_argument('--n_clusters', type=int, default=n_clusters,\n",
    "                        help='number of clusters in Kmeans, when ground truth label is not avalible.')  # 5 on MERFISH, 20 on Breast\n",
    "    parser.add_argument('--draw_map', type=int,\n",
    "                        default=1, help='run drawing map')\n",
    "    parser.add_argument('--diff_gene', type=int, default=0,\n",
    "                        help='Run differential gene expression analysis')\n",
    "    args = parser.parse_args(args=['--data_type', \"nsc\",\n",
    "                                   '--data_path', '../../Dataset/',\n",
    "                                   '--model_path', '../../Output/',\n",
    "                                   '--embedding_data_path', '../../Output/',\n",
    "                                   '--result_path', '../../Output/',\n",
    "                                   ])\n",
    "    args.num_epoch = 5\n",
    "    if dataset in [\"Mouse_brain\",\"Breast_cancer\",\"PDAC\"]:\n",
    "        args.data_type = 'nsc'\n",
    "        args.lambda_I = 0.3\n",
    "    elif dataset in [\"Stereo\",\"STARmap\",\"SeqFish\"]:\n",
    "        args.data_type = 'sc'\n",
    "        args.lambda_I = 0.8\n",
    "\n",
    "\n",
    "    args.data_path =read_data_path\n",
    "    save_path = save_data_path\n",
    "    mk_dir(save_path)\n",
    "    args.result_path = save_path\n",
    "    args.model_path = save_path\n",
    "    args.embedding_data_path = save_path\n",
    "    args.result_path=save_path\n",
    "\n",
    "    if not os.path.exists(args.embedding_data_path):\n",
    "        os.makedirs(args.embedding_data_path)\n",
    "    if not os.path.exists(args.model_path):\n",
    "        os.makedirs(args.model_path)\n",
    "\n",
    "    print('------------------------Model and Training Details--------------------------')\n",
    "    print(args)\n",
    "\n",
    "    if args.data_type == 'sc':  # should input a single cell resolution dataset, e.g. MERFISH\n",
    "        from CCST_merfish_utils import CCST_on_MERFISH\n",
    "        sc_score=CCST_on_MERFISH(args)\n",
    "    elif args.data_type == 'nsc':  # should input a non-single cell resolution dataset, e.g. V1_Breast_Cancer_Block_A_Section_1\n",
    "        from CCST_ST_utils import CCST_on_ST\n",
    "        sc_score=CCST_on_ST(args)\n",
    "    else:\n",
    "        print('Data type not specified')\n",
    "    return sc_score\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================The data running now is：151673=============================\n",
      "------------------------Model and Training Details--------------------------\n",
      "Namespace(DGI=1, PCA=1, cluster=1, data_name='151673', data_path='../../Dataset/CCST_generate_dataset/DLPFC/151673/', data_type='nsc', diff_gene=0, draw_map=1, embedding_data_path='../../Output/CCST/DLPFC/151673/', hidden=256, lambda_I=0.3, load=0, model_path='../../Output/CCST/DLPFC/151673/', n_clusters=7, num_epoch=5, result_path='../../Output/CCST/DLPFC/151673/', save_path='../../Output/CCST/DLPFC/151673/')\n",
      "Adj: (3639, 3639) Edges: 24763\n",
      "X: (3639, 200)\n",
      "-----------Deep Graph Infomax-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_install\\envs\\STAGATE\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time in seconds:  1\n",
      "-----------Clustering-------------\n",
      "Shape of data to PCA: (3639, 256)\n",
      "Shape of data output by PCA: (3639, 30)\n",
      "PCA recover: 0.91361886\n",
      "Shape of data to cluster: (3639, 30)\n",
      " SC_Score: 0.27627426\n",
      "Average Silhouette Width (ASW): 0.27627426\n",
      "SC_revise: 0.049663212\n",
      "********************************预测结果输出**********************：\n",
      "ari, nmi, ami,SC,ASW: 0.32344212182660814 0.5477277343011339 0.5462703220951153 0.27627426 0.27627426\n",
      "used time and memory： 8.998385429382324 2.5001296997070312\n",
      "pred.shape: (3639, 3)\n",
      "              ari       nmi      ami        sc      time   memory  round\n",
      "dataset                                                                 \n",
      "151673   0.323442  0.547728  0.54627  0.276274  8.998385  2.50013      0\n"
     ]
    }
   ],
   "source": [
    "n_clusters_map = {\"Stereo\": 16, \"STARmap\": 16, \"SeqFish\": 22,\"DLPFC\": '5-7', \"Breast_cancer\": 20, \"Mouse_brain\": 15,\"PDAC\": 4}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Dataset1 = ['151507', '151508', '151509', '151510', '151669', '151670', '151671', '151672', '151673', '151674', '151675', '151676']\n",
    "    # Dataset2=[\"Mouse_brain\",\"Breast_cancer\",\"PDAC\",\"SeqFish\",\"Stereo\",\"STARmap\"]\n",
    "    Dataset_test = ['151673']\n",
    "\n",
    "    for dataset in Dataset_test:\n",
    "        print(f\"==============================The data running now is：{dataset}=============================\")\n",
    "        if dataset.startswith('15'): #if Dataset is DLPFC\n",
    "            read_data_path=f'../../Dataset/CCST_generate_dataset/DLPFC/{dataset}/'\n",
    "            save_data_path = f'../../Output/CCST/DLPFC/{dataset}/'\n",
    "            cluster_num = 5 if dataset in ['151669', '151670', '151671', '151672'] else 7\n",
    "        else:\n",
    "            read_data_path = f'../../Dataset/CCST_generate_dataset/{dataset}/'\n",
    "            save_data_path = f'../../Output/CCST/{dataset}/'\n",
    "            cluster_num = n_clusters_map[dataset]\n",
    "\n",
    "        if not os.path.exists(save_data_path):\n",
    "            os.makedirs(save_data_path)\n",
    "\n",
    "        results = pd.DataFrame()\n",
    "        best_ari = 0\n",
    "        for i in range(1):\n",
    "            start = time.time()\n",
    "            start_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024  #\n",
    "            SC=run_CCST(dataset, cluster_num,read_data_path,save_data_path)\n",
    "            end = time.time()\n",
    "            end_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024  #\n",
    "            usd_time=end-start\n",
    "            used_memory=end_MB-start_MB\n",
    "            print(\"used time and memory：\",  usd_time, used_memory)\n",
    "\n",
    "            pred = pd.read_csv(f'{save_data_path}predict_types.csv')\n",
    "            print(\"pred.shape:\",pred.shape)\n",
    "            ari, nmi,ami = eval_model(pred.iloc[:,2],pred.iloc[:,1])\n",
    "            res = {}\n",
    "\n",
    "            res[\"dataset\"] = dataset\n",
    "            res[\"ari\"] = ari\n",
    "            res[\"nmi\"] = nmi\n",
    "            res[\"ami\"]=ami\n",
    "            res[\"sc\"]=SC\n",
    "            res[\"time\"] = usd_time\n",
    "            res[\"memory\"]=used_memory\n",
    "            res[\"round\"] = i\n",
    "\n",
    "            results = results._append(res, ignore_index=True)\n",
    "\n",
    "        results.to_csv(f'{save_data_path}{dataset}_result.csv', header=True)\n",
    "        results.set_index('dataset', inplace=True)\n",
    "        print(results.head())\n",
    "        res_mean = results.mean()\n",
    "        res_mean.to_csv(f'{save_data_path}{dataset}_mean.csv', header=True)\n",
    "        res_std = results.std()\n",
    "        res_std.to_csv(f'{save_data_path}{dataset}_std.csv', header=True)\n",
    "        res_median = results.median()\n",
    "        res_median.to_csv(f'{save_data_path}{dataset}_median.csv', header=True) #\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
