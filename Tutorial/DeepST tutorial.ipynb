{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from DeepST import run\n",
    "import pandas as pd\n",
    "from sklearn.metrics.cluster import adjusted_rand_score,normalized_mutual_info_score,adjusted_mutual_info_score,silhouette_score\n",
    "import os\n",
    "import psutil,time,tracemalloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def eval_model(pred, labels=None):\n",
    "    if labels is not None:\n",
    "        label_df = pd.DataFrame({\"True\": labels, \"Pred\": pred}).dropna()\n",
    "        # label_df = pd.DataFrame({\"True\": labels, \"Pred\": pred}).dropna()\n",
    "        # completeness = completeness_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        # hm = homogeneity_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        ari = adjusted_rand_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        nmi = normalized_mutual_info_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        ami=adjusted_mutual_info_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "    return  ari,nmi,ami\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151673 has 7 cluster type!\n",
      "===training epoch:1====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_install\\envs\\STAGATE\\lib\\site-packages\\anndata\\_core\\anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "Tiling image: 100%|██████████ [ time left: 00:00 ]\n",
      "D:\\Anaconda_install\\envs\\STAGATE\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda_install\\envs\\STAGATE\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extract image feature: 100%|██████████ [ time left: 00:00 ]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image feature is added to adata.obsm['image_feat'] !\n",
      "The pca result of image feature is added to adata.obsm['image_feat_pca'] !\n",
      "Physical distance calculting Done!\n",
      "The number of nearest tie neighbors in physical distance is: 31.45452047265732\n",
      "Gene correlation calculting Done!\n",
      "Morphological similarity calculting Done!\n",
      "The weight result of image feature is added to adata.obsm['weights_matrix_all'] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find adjacent spots of each spot: 100%|██████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Augment molecule expression is Done!\n",
      "12.0000 neighbors per cell on average.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_install\\envs\\STAGATE\\lib\\site-packages\\DeepST\\adj.py:175: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj_org = nx.adjacency_matrix(nx.from_dict_of_lists(graphdict))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0000 neighbors per cell on average.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_install\\envs\\STAGATE\\lib\\site-packages\\DeepST\\adj.py:175: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj_org = nx.adjacency_matrix(nx.from_dict_of_lists(graphdict))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Graph computing is Done!\n",
      "Your task is in full swing, please wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepST trains an initial model: 100%|██████████ [ time left: 00:00 ]\n",
      "DeepST trains a final model:   0%|           [ time left: ? ]D:\\Anaconda_install\\envs\\STAGATE\\lib\\site-packages\\torch\\nn\\functional.py:2916: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "DeepST trains a final model: |           [ time left: 00:00 ]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: DeepST training has been Done!\n",
      "Your task has been completed, thank you\n",
      "Of course, you can also perform downstream analysis on the processed data\n",
      "Best resolution:  0.32999999999999985\n",
      "Current memory usage_end:：1.3129 GB\n",
      "time: 291.0246 s\n",
      "memory blocks peak:    5.7791 GB\n",
      "  dataset      ari       nmi       ami        sc        time      Memo  \\\n",
      "0  151673  0.53586  0.681391  0.680485  0.143846  291.024647  1.312862   \n",
      "\n",
      "   Memo_peak  round  \n",
      "0   5.779141      1  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    " method = 'DeepST'\n",
    "n_clusters_map= {\"Stereo\": 16, \"STARmap\": 16, \"SeqFish\": 22, \"Breast_cancer\": 20, \"Mouse_brain\": 15,\"PDAC\": 4}\n",
    "# dataset1= [\"Stereo\",\"Breast_cancer\", \"Mouse_brain\"]\n",
    "# dataset2 = ['151507', '151508', '151509', '151510','151669', '151670', '151671', '151672', '151673', '151674', '151675', '151676']\n",
    "dataset=['151673']\n",
    "\n",
    "for data_name in dataset:\n",
    "    if data_name.startswith('15'):\n",
    "        data_path = '../../Dataset/DLPFC/'\n",
    "        save_root =f'../../Output/DeepST/DLPFC/{data_name}/'\n",
    "    else:\n",
    "        data_path = '../../Dataset/'\n",
    "        save_root = f'../../Output/DeepST/{data_name}/'\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "    #get the DLPFC Clustering number\n",
    "    if  data_name.startswith('15'):\n",
    "        n_domains= 5 if data_name in ['151669', '151670', '151671', '151672'] else 7\n",
    "    else:\n",
    "        n_domains  = n_clusters_map[data_name]\n",
    "    print(f\"{data_name} has {n_domains} cluster type!\")\n",
    "\n",
    "    results = pd.DataFrame()\n",
    "    for i in range(1):\n",
    "        num=i+1\n",
    "        print(\"===training epoch:{}====\".format(num))\n",
    "        start = time.time()\n",
    "        tracemalloc.start()\n",
    "        start_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024\n",
    "        deepen = run(\n",
    "            save_path = save_root,\n",
    "            task = \"Identify_Domain\", #### DeepST includes two tasks, one is \"Identify_Domain\" and the other is \"Integration\"\n",
    "            pre_epochs = 800, #### pre_epochs = 800,  choose the number of training\n",
    "            epochs = 1000, #### epochs = 1000,choose the number of training\n",
    "            use_gpu = True)\n",
    "\n",
    "        ###### (1)read adata\n",
    "        if  data_name.startswith('15') or data_name in [\"Breast_cancer\", \"Mouse_brain\"]:\n",
    "            adata = deepen._get_adata(platform=\"Visium\", data_path=data_path, data_name=data_name)\n",
    "        elif  data_name =='PDAC':\n",
    "            adata = deepen._get_adata(platform=\"ST\", data_path=data_path, data_name=data_name)\n",
    "        else:\n",
    "            adata = deepen._get_adata(platform=\"StereoSeq\", data_path=data_path, data_name=data_name)\n",
    "\n",
    "        ###### (2) Segment the Morphological Image\n",
    "        adata = deepen._get_image_crop(adata, data_name=data_name) #未经PCA的结果保存在：adata.obsm['image_feat']\n",
    "\n",
    "        ###### (3)ata augmentation. spatial_type includes three kinds of \"KDTree\", \"BallTree\" and \"LinearRegress\", among which \"LinearRegress\"\n",
    "        adata = deepen._get_augment(adata, spatial_type=\"LinearRegress\", use_morphological=True)\n",
    "\n",
    "        ###### (4)Build graphs. \"distType\" includes \"KDTree\", \"BallTree\", \"kneighbors_graph\", \"Radius\", etc., see adj.py\n",
    "        graph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"BallTree\")\n",
    "\n",
    "        ###### (5)Enhanced data preprocessing\n",
    "        data = deepen._data_process(adata, pca_n_comps = 200)  #图像特征用RSNET50 处理完后，保存在这     adata.obsm[\"X_morphology\"] = pca.transform(feature_df.transpose().to_numpy())\n",
    "\n",
    "        ###### (6)Training models\n",
    "        deepst_embed = deepen._fit(\n",
    "            data = data,\n",
    "            graph_dict = graph_dict,\n",
    "        )\n",
    "\n",
    "        adata.obsm[\"DeepST_embed\"] = deepst_embed\n",
    "        ###### Define the number of space domains, and the model can also be customized. If it is a model custom priori = False.\n",
    "        adata = deepen._get_cluster_data(adata, n_domains=n_domains, priori = True) #The refine result save in：'DeepST_refine_domain'\n",
    "        adata.obs['DeepST'] = adata.obs['DeepST_refine_domain']\n",
    "\n",
    "        ###### Spatial localization map of the spatial domain\n",
    "        # sc.pl.spatial(adata, color='DeepST_refine_domain', frameon = False, spot_size=15)\n",
    "        # plt.savefig(os.path.join(save_root, f'{data_name}_domains.pdf'), bbox_inches='tight', dpi=300)\n",
    "        ###（7） Calculating outcome indicators\n",
    "        end = time.time()\n",
    "        end_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024\n",
    "        uesd_time = end - start\n",
    "        used_memo = end_MB - start_MB\n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        tracemalloc.stop()\n",
    "        peak = peak / 1024.0 / 1024.0 / 1024.0\n",
    "        print(u'Current memory usage_end:：%.4f GB' % used_memo)\n",
    "        print('time: {:.4f} s'.format(uesd_time))\n",
    "        print('memory blocks peak:{:>10.4f} GB'.format(peak))\n",
    "        tracemalloc.clear_traces()\n",
    "\n",
    "        ari, nmi, ami = eval_model(adata.obs['DeepST'], adata.obs['ground_truth'])\n",
    "        SC = silhouette_score(adata.obsm[\"DeepST_embed\"], adata.obs['DeepST'])\n",
    "        used_adata = adata[adata.obs[\"ground_truth\"].notna()]  # ccc\n",
    "\n",
    "        res = {}\n",
    "        res[\"dataset\"] = data_name\n",
    "        res[\"ari\"] = ari\n",
    "        res[\"nmi\"] = nmi\n",
    "        res[\"ami\"] = ami\n",
    "        res[\"sc\"] = SC\n",
    "        res[\"time\"] = uesd_time\n",
    "        res[\"Memo\"] = used_memo\n",
    "        res[\"Memo_peak\"] = peak\n",
    "        res[\"round\"] = i + 1\n",
    "        results = results._append(res, ignore_index=True)\n",
    "    print(results.head())\n",
    "    results.to_csv(f'{save_root}/{data_name}_result.csv')\n",
    "\n",
    "    results.set_index('dataset', inplace=True)\n",
    "    res_mean = results.mean()\n",
    "    res_mean.to_csv(f'{save_root}{data_name}_mean.csv', header=True)\n",
    "    res_std = results.std()\n",
    "    res_std.to_csv(f'{save_root}{data_name}_std.csv', header=True)\n",
    "    res_median = results.median()\n",
    "    res_median.to_csv(f'{save_root}{data_name}_median.csv', header=True)  #\n",
    "\n",
    "    adata.write(f'{save_root}/DeepST_{data_name}.h5ad')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
