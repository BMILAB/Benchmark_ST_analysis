{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import psutil,tracemalloc\n",
    "from sklearn.metrics.cluster import adjusted_rand_score,normalized_mutual_info_score,adjusted_mutual_info_score,silhouette_score\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def mk_dir(input_path):\n",
    "    if not os.path.exists(input_path):\n",
    "        os.makedirs(input_path)\n",
    "    return input_path\n",
    "\n",
    "def eval_model(pred, labels=None):\n",
    "    if labels is not None:\n",
    "        label_df = pd.DataFrame({\"True\": labels, \"Pred\": pred}).dropna()\n",
    "        # label_df = pd.DataFrame({\"True\": labels, \"Pred\": pred}).dropna()\n",
    "        # completeness = completeness_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        # hm = homogeneity_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        ari = adjusted_rand_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        nmi = normalized_mutual_info_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "        ami=adjusted_mutual_info_score(label_df[\"True\"], label_df[\"Pred\"])\n",
    "    return  ari,nmi,ami"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def run_SpaGCN(adata, dataset, random_seed = np.random.randint(100),\n",
    "                device=torch.device('cuda:1' if torch.cuda.is_available() else 'cpu'),\n",
    "                save_data_path=\"/home/sda1/fangzy/data/st_data/Benchmark/SpaGCN/\"):\n",
    "    import numpy as np\n",
    "    # import SpaGCN as spg\n",
    "    import SpaGCN_raw as spg\n",
    "    import random, torch\n",
    "    import cv2\n",
    "\n",
    "\n",
    "    ##### Spatial domain detection using SpaGCN\n",
    "    spg.prefilter_genes(adata, min_cells=3) # avoiding all genes are zeros\n",
    "    spg.prefilter_specialgenes(adata)\n",
    "    #Normalize and take log for UMI\n",
    "    sc.pp.normalize_per_cell(adata)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "\n",
    "    ######  As there is no image, the distance is calculated directly from the coordinates#########################\n",
    "    x_array = adata.obs[\"x_array\"].tolist()\n",
    "    y_array = adata.obs[\"y_array\"].tolist()\n",
    "    x_pixel=x_array\n",
    "    y_pixel=y_array\n",
    "    adj = spg.calculate_adj_matrix(x=x_array, y=y_array, histology=False)\n",
    "\n",
    "    p=0.5\n",
    "    l=spg.search_l(p, adj, start=0.01, end=1000, tol=0.01, max_run=100)\n",
    "\n",
    "    n_clusters = len(set(adata.obs[\"ground_truth\"].dropna()))\n",
    "    r_seed=t_seed=n_seed=random_seed\n",
    "    res=spg.search_res(adata, adj, l, n_clusters, start=0.7, step=0.1,\n",
    "                       tol=5e-3, lr=0.05, max_epochs=20, r_seed=r_seed,\n",
    "                       t_seed=t_seed, n_seed=n_seed)\n",
    "\n",
    "    ### 4.3 Run SpaGCN\n",
    "    clf=spg.SpaGCN()\n",
    "    clf.set_l(l)\n",
    "    # Set seed\n",
    "    random.seed(r_seed)\n",
    "    torch.manual_seed(t_seed)\n",
    "    np.random.seed(n_seed)\n",
    "    #Run\n",
    "    clf.train(adata, adj, init_spa=True, init=\"louvain\",\n",
    "              res=res, tol=5e-3, lr=0.05, max_epochs=200)\n",
    "    emb,y_pred, prob=clf.predict()\n",
    "\n",
    "    adata.obs[\"pred\"]= y_pred\n",
    "    adata.obs[\"pred\"]=adata.obs[\"pred\"].astype('category')\n",
    "    adata.obsm[\"embedding\"]=emb\n",
    "\n",
    "    if dataset.startswith('15'):\n",
    "        dataset='DLPFC'\n",
    "    else:\n",
    "        dataset=dataset\n",
    "    refine_map = {\"Breast_cancer\": \"hexagon\", \"Mouse_brain\": \"hexagon\", \"DLPFC\": \"hexagon\", \"PDAC\": \"square\"}\n",
    "\n",
    "    #Do cluster refinement(optional)\n",
    "    # shape=\"hexagon\" for Visium data, \"square\" for ST data.\n",
    "    adj_2d=spg.calculate_adj_matrix(x=x_array, y=y_array, histology=False)\n",
    "    refined_pred=spg.refine(sample_id=adata.obs.index.tolist(),\n",
    "                            pred=adata.obs[\"pred\"].tolist(), dis=adj_2d,\n",
    "                            shape=refine_map[dataset])\n",
    "    adata.obs[\"refined_pred\"]=refined_pred\n",
    "    adata.obs[\"refined_pred\"]=adata.obs[\"refined_pred\"].astype('category')\n",
    "\n",
    "\n",
    "    ari, nmi, ami = eval_model(adata.obs['pred'], adata.obs['ground_truth'])\n",
    "    SC = silhouette_score(adata.obsm[\"embedding\"], adata.obs['pred'])\n",
    "\n",
    "    used_adata = adata[adata.obs[\"ground_truth\"].notna()]\n",
    "    SC_revise = silhouette_score(used_adata.obsm[\"embedding\"], used_adata.obs['ground_truth'])\n",
    "\n",
    "\n",
    "    ari_r, nmi_r, ami_r = eval_model(adata.obs['refined_pred'], adata.obs['ground_truth'])  # 因为结果都保存在domain中\n",
    "    SC_r = silhouette_score(adata.obsm[\"embedding\"], adata.obs['refined_pred'])\n",
    "    SC_r_revise = silhouette_score(used_adata.obsm[\"embedding\"], used_adata.obs['refined_pred'])\n",
    "    res = {}\n",
    "    res[\"dataset\"] = dataset\n",
    "    res[\"ari\"] = ari\n",
    "    res[\"nmi\"] = nmi\n",
    "    res[\"ami\"] = ami\n",
    "    res[\"sc\"] = SC\n",
    "    res['SC_revise'] = SC_revise\n",
    "\n",
    "    res[\"nmi_r\"] = nmi_r\n",
    "    res[\"ari_r\"] = ari_r\n",
    "    res[\"ami_r\"] = ami_r\n",
    "    res[\"sc_r\"] = SC_r\n",
    "    res['SC_r_revise']=SC_r_revise\n",
    "    return res, adata\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load DLPFC dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_install\\envs\\STAGATE\\lib\\site-packages\\anndata\\_core\\anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Training epoch:1====\n",
      "recommended l =  0.6813800048828125\n",
      "Start at res =  0.7 step =  0.1\n",
      "Initializing cluster centers with louvain, resolution =  0.7\n",
      "Epoch  0\n",
      "Epoch  10\n",
      "Res =  0.7 Num of clusters =  7\n",
      "recommended res =  0.7\n",
      "Initializing cluster centers with louvain, resolution =  0.7\n",
      "Epoch  0\n",
      "Epoch  10\n",
      "Epoch  20\n",
      "Epoch  30\n",
      "Epoch  40\n",
      "Epoch  50\n",
      "Epoch  60\n",
      "Epoch  70\n",
      "Epoch  80\n",
      "Epoch  90\n",
      "Epoch  100\n",
      "Epoch  110\n",
      "Epoch  120\n",
      "Epoch  130\n",
      "Epoch  140\n",
      "Epoch  150\n",
      "Epoch  160\n",
      "Epoch  170\n",
      "Epoch  180\n",
      "Epoch  190\n",
      "Current memory usage_end:：0.0556 GB\n",
      "time: 17.1843 s\n",
      "memory blocks peak:    1.1023 GB\n",
      "              ari       nmi       ami        sc  SC_revise     nmi_r  \\\n",
      "dataset                                                                \n",
      "DLPFC    0.431516  0.578393  0.577253  0.365437   0.159713  0.610935   \n",
      "\n",
      "            ari_r     ami_r      sc_r  SC_r_revise       time      Memo  \\\n",
      "dataset                                                                   \n",
      "DLPFC    0.457466  0.609883  0.343638     0.346671  17.184329  0.055626   \n",
      "\n",
      "         Memo_peak  round  \n",
      "dataset                    \n",
      "DLPFC     1.102297      1  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils_for_all as usa\n",
    "if __name__ == '__main__':\n",
    "\n",
    " Dataset= [\"Mouse_brain\", \"Breast_cancer\", \"PDAC\", \"SeqFish\", \"Stereo\", \"STARmap\", '151507', '151508']\n",
    "Dataset_test = ['151673']\n",
    "\n",
    "for dataset in Dataset_test:\n",
    "    if dataset.startswith('15'):\n",
    "        save_path=f'../../Output/SpaGCN/DLPFC/{dataset}/Has_HE/'\n",
    "    else:\n",
    "        save_path = f'../../Output/SpaGCN/{dataset}/Has_HE/'\n",
    "    mk_dir(save_path)\n",
    "\n",
    "    adata, n_cluster = usa.get_adata(dataset, data_path='../../Dataset/')\n",
    "    adata.var_names_make_unique()\n",
    "    random_seed = np.random.randint(100)\n",
    "\n",
    "    results = pd.DataFrame()\n",
    "    for i in range(1):\n",
    "        num = i + 1\n",
    "        print(\"===Training epoch:{}====\".format(num))\n",
    "        start = time.time()\n",
    "        tracemalloc.start()\n",
    "        start_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024\n",
    "\n",
    "        res, adata_h5 = run_SpaGCN(adata.copy(), dataset, random_seed=random_seed)\n",
    "\n",
    "        end = time.time()\n",
    "        end_MB = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024\n",
    "        uesd_time = end - start\n",
    "        used_memo = end_MB - start_MB\n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        tracemalloc.stop()\n",
    "        peak = peak / 1024.0 / 1024.0 / 1024.0\n",
    "        print(u'Current memory usage_end:：%.4f GB' % used_memo)\n",
    "        print('time: {:.4f} s'.format(uesd_time))\n",
    "        print('memory blocks peak:{:>10.4f} GB'.format(peak))\n",
    "        tracemalloc.clear_traces()\n",
    "\n",
    "        res[\"time\"] = uesd_time\n",
    "        res[\"Memo\"] = used_memo\n",
    "        res[\"Memo_peak\"] = peak\n",
    "        res[\"round\"] = i + 1\n",
    "        results = results._append(res, ignore_index=True)\n",
    "\n",
    "    adata_h5.write_h5ad(save_path + str(dataset) + \".h5ad\")\n",
    "    results.to_csv(save_path +\"/res_result.csv\", header=True)\n",
    "    results.set_index('dataset', inplace=True)\n",
    "    print(results.head())\n",
    "    res_mean = results.mean()\n",
    "    res_mean.to_csv(f'{save_path}{dataset}_mean.csv', header=True)\n",
    "    res_std = results.std()\n",
    "    res_std.to_csv(f'{save_path}{dataset}_std.csv', header=True)\n",
    "    res_median = results.median()\n",
    "    res_median.to_csv(f'{save_path}{dataset}_median.csv', header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
